{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "214ba0bc",
   "metadata": {},
   "source": [
    "### 1. Concatenate final_data_2.csv to final_data_8.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a11534dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a list of file names from 2 to 8\n",
    "files = [f\"final_data_{i}.csv\" for i in range(2, 9)]\n",
    "\n",
    "# Read and concatenate\n",
    "df = pd.concat((pd.read_csv(f) for f in files), ignore_index=True)\n",
    "\n",
    "# Save result\n",
    "df.to_csv(\"combined_2_to_8.csv\", index=False)\n",
    "\n",
    "#print(\"CSV files final_data_2.csv to final_data_8.csv concatenated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc16b708",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0m/d4xwfvr11f9g7yflwxh0w_c40000gn/T/ipykernel_48221/597043288.py:15: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  filtered_df = df_combined[~df_combined['text'].astype(str).str.contains(combined_pattern, regex=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! 2 rows removed. 65578 rows kept.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Load the combined file\n",
    "df_combined = pd.read_csv(\"combined_2_to_8.csv\")\n",
    "\n",
    "# Define regex patterns\n",
    "link_pattern = r\"(https?://\\S+|www\\.\\S+)\"       # http://, https://, www.\n",
    "email_pattern = r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\"  # emails\n",
    "phone_pattern = r\"\\b(?:\\+?\\d{1,3})?[-.\\s]?\\(?\\d{2,4}\\)?[-.\\s]?\\d{3,4}[-.\\s]?\\d{3,4}\\b\"  # phone numbers\n",
    "\n",
    "# Combine into one pattern\n",
    "combined_pattern = f\"({link_pattern}|{email_pattern}|{phone_pattern})\"\n",
    "\n",
    "# Filter out rows that match\n",
    "filtered_df = df_combined[~df_combined['text'].astype(str).str.contains(combined_pattern, regex=True)]\n",
    "\n",
    "# Save result\n",
    "filtered_df.to_csv(\"filtered_combined.csv\", index=False)\n",
    "\n",
    "print(f\"Done! {len(df_combined) - len(filtered_df)} rows removed. {len(filtered_df)} rows kept.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d9f8f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote rows 0-9999 to final_data_2_filtered.csv\n",
      "Wrote rows 10000-19999 to final_data_3_filtered.csv\n",
      "Wrote rows 20000-29999 to final_data_4_filtered.csv\n",
      "Wrote rows 30000-39999 to final_data_5_filtered.csv\n",
      "Wrote rows 40000-49999 to final_data_6_filtered.csv\n",
      "Wrote rows 50000-59999 to final_data_7_filtered.csv\n",
      "Wrote rows 60000-65577 to final_data_8_filtered.csv\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "\n",
    "INPUT_FILE = \"filtered_combined.csv\"\n",
    "CHUNK_SIZE = 10_000\n",
    "START_IDX = 2   # first output index\n",
    "END_IDX = 8     # last output index\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "# Handle empty file\n",
    "if df.empty:\n",
    "    print(\"No rows in filtered_combined.csv â€” nothing to split.\")\n",
    "else:\n",
    "    num_chunks = math.ceil(len(df) / CHUNK_SIZE)\n",
    "    max_slots = END_IDX - START_IDX + 1\n",
    "\n",
    "    if num_chunks > max_slots:\n",
    "        print(f\"Warning: You have {num_chunks} chunks but only {max_slots} filenames (2..8).\")\n",
    "        print(\"Only the first 7 files will be written with the requested names.\")\n",
    "\n",
    "    for i in range(num_chunks):\n",
    "        start = i * CHUNK_SIZE\n",
    "        end = min((i + 1) * CHUNK_SIZE, len(df))\n",
    "        chunk = df.iloc[start:end]\n",
    "\n",
    "        out_idx = START_IDX + i\n",
    "        if out_idx > END_IDX:\n",
    "            # Stop if you strictly only want 2..8\n",
    "            # Break here to enforce the naming constraint:\n",
    "            # break\n",
    "            #\n",
    "            # Or, if you'd prefer to keep writing additional files beyond 8, uncomment below:\n",
    "            # pass  # out_idx can continue to 9, 10, ...\n",
    "            print(f\"Reached file index {END_IDX}. Skipping extra chunk {i+1}/{num_chunks}.\")\n",
    "            break\n",
    "\n",
    "        out_name = f\"final_data_{out_idx}_filtered.csv\"\n",
    "        chunk.to_csv(out_name, index=False)\n",
    "        print(f\"Wrote rows {start}-{end-1} to {out_name}\")\n",
    "\n",
    "    print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59938e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c950041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
