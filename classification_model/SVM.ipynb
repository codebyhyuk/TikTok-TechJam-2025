{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data from CSV files...\n",
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"\\nLoading data from CSV files...\")\n",
    "    # load the 5D feature data\n",
    "    X = pd.read_csv('/Users/yumin/Documents/GitHub/TikTok-TechJam-2025/feature_engineering_model/temp.csv')\n",
    "\n",
    "    # load the binary ground truth labels\n",
    "    y = pd.read_csv('/Users/yumin/Documents/GitHub/TikTok-TechJam-2025/data_gpt_labeler/final_data_labeled_1.csv')\n",
    "    \n",
    "    # check if the required columns exist\n",
    "    required_features = ['A', 'B', 'D2', 'E', 'G']\n",
    "    if not all(col in X.columns for col in required_features):\n",
    "        print(f\"Error: features.csv must contain columns {required_features}.\")\n",
    "        exit()\n",
    "\n",
    "    required_label = 'policy_label'\n",
    "    if required_label not in y.columns:\n",
    "        print(f\"Error: final_data_labeled_1.csv must contain a '{required_label}' column.\")\n",
    "        exit()\n",
    "\n",
    "    print(\"Data loaded successfully.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: One or both of the CSV files (features.csv, labels.csv) were not found.\")\n",
    "    print(\"Please make sure they are in the same directory as this script.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy_label\n",
      "1    8910\n",
      "0    1090\n",
      "Name: count, dtype: int64\n",
      "             A         B        D2         E         G\n",
      "0     0.126823  0.581653  0.660104  0.993421  0.999407\n",
      "1     0.066522  0.565305  0.620909  0.360918  0.997275\n",
      "2     0.158263  0.575038  0.551840  0.987322  0.999049\n",
      "3     0.062633  0.575837  0.630236  0.859828  0.999422\n",
      "4     0.005904  0.572793  0.792418  0.901759  0.999557\n",
      "...        ...       ...       ...       ...       ...\n",
      "9995  0.353107  0.584095  0.609373  0.986010  0.999477\n",
      "9996  0.407681  0.572810  0.561827  0.803679  0.999491\n",
      "9997  0.129818  0.583600  0.596096  0.905910  0.999499\n",
      "9998  0.024677  0.561784  0.500000  0.767955  0.999611\n",
      "9999  0.298661  0.572159  0.588138  0.982511  0.999352\n",
      "\n",
      "[10000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y['policy_label'].value_counts())\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing undersampling to balance the dataset...\n",
      "Original number of samples: 10000\n",
      "Balanced number of samples: 2180\n",
      "Undersampling complete.\n"
     ]
    }
   ],
   "source": [
    "# undersampling majority class\n",
    "def undersample_data(X_data, y_data):\n",
    "    # combine features and labels into a single DataFrame for easy manipulation\n",
    "    combined_df = pd.concat([X_data, y_data], axis=1)\n",
    "\n",
    "    # separate majority and minority classes\n",
    "    majority_class = combined_df[combined_df['policy_label'] == 1]\n",
    "    minority_class = combined_df[combined_df['policy_label'] == 0]\n",
    "\n",
    "    # check for empty minority class\n",
    "    if minority_class.empty:\n",
    "        print(\"Warning: Minority class is empty. Cannot perfom undersampling.\")\n",
    "        return X_data, y_data\n",
    "\n",
    "    # undersample the majority class to match the number of samples in the minority class\n",
    "    undersampled_majority = majority_class.sample(\n",
    "        n=len(minority_class), \n",
    "        replace=False, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    balanced_df = pd.concat([undersampled_majority, minority_class])\n",
    "\n",
    "    # shuffle the combined df to ensure samples are not ordered by class\n",
    "    balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # split the balanced df back into features (X_balanced) and labels (y_balanced)\n",
    "    X_balanced = balanced_df.drop('policy_label', axis=1)\n",
    "    y_balanced = balanced_df['policy_label']\n",
    "\n",
    "    print(f\"Original number of samples: {len(combined_df)}\")\n",
    "    print(f\"Balanced number of samples: {len(balanced_df)}\")\n",
    "    print(\"Undersampling complete.\")\n",
    "\n",
    "    return X_balanced, y_balanced\n",
    "\n",
    "X_balanced, y_balanced = undersample_data(X, y['policy_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       1\n",
      "2       1\n",
      "3       0\n",
      "4       1\n",
      "       ..\n",
      "2175    0\n",
      "2176    0\n",
      "2177    0\n",
      "2178    0\n",
      "2179    1\n",
      "Name: policy_label, Length: 2180, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             A         B        D2         E         G\n",
      "0     0.058882  0.558941  0.324697  0.990225  0.999323\n",
      "1     0.006189  0.551747  0.644799  0.993508  0.999353\n",
      "2     0.245700  0.607392  0.633163  0.969169  0.999559\n",
      "3     0.010014  0.526322  0.000000  0.847382  0.989642\n",
      "4     0.135020  0.577114  0.710586  0.982642  0.999343\n",
      "...        ...       ...       ...       ...       ...\n",
      "2175  0.008589  0.531942  0.000000  0.884126  0.991157\n",
      "2176  0.009070  0.538217  0.500000  0.858099  0.999559\n",
      "2177  0.011487  0.552040  0.688271  0.842453  0.999393\n",
      "2178  0.012410  0.565927  0.597343  0.575527  0.999489\n",
      "2179  0.158671  0.584328  0.668578  0.770834  0.999300\n",
      "\n",
      "[2180 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting data into training and testing sets...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_balanced, y_balanced, test_size=0.2, random_state=42, stratify=y_balanced\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1744 samples\n",
      "Testing set size: 436 samples\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing and training the SVM classifier...\n",
      "SVM model training complete.\n"
     ]
    }
   ],
   "source": [
    "# training the SVM classifier\n",
    "model = SVC(kernel='linear', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"SVM model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the model on the test set...\n",
      "Model Accuracy: 0.61\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.44      0.53       218\n",
      "           1       0.58      0.77      0.66       218\n",
      "\n",
      "    accuracy                           0.61       436\n",
      "   macro avg       0.62      0.61      0.60       436\n",
      "weighted avg       0.62      0.61      0.60       436\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
